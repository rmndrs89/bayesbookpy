[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Data Analysis with Python",
    "section": "",
    "text": "Preface\nThis book is about doing data analysis in Python using a Bayesian approach. The contents are mainly based on the Coursera specialization about Bayesian Statistics (Heiner et al. n.d.), but will gradually be supplemented with practical examples and additional theory from other resources such as Doing Bayesian Data Analysis (Kruschke 2015).\n\n\n\n\nHeiner, Matthew, Herbert Lee, Abel Rodriguez, Raquel Prado, and Jizhou Kang. n.d. “Bayesian Statistics.” Coursera.\n\n\nKruschke, John K. 2015. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. 2nd ed. Academic Press.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/01_concepts_and_data_analysis/01_01_intro.html",
    "href": "chapters/01_concepts_and_data_analysis/01_01_intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Kruschke (2015) for additional discussion of literate programming.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats\n\nxs = np.linspace(-5, 5, num=500, endpoint=False)\nys = scipy.stats.norm.pdf(x=xs, loc=0.0, scale=1)\nfig, ax = plt.subplots(figsize=(2.8, 2.8))\nax.plot(xs, ys, lw=2, c=\"gray\")\nax.set_xlabel(f\"$x$\")\nax.set_ylabel(f\"$p(x)$\")\nax.set_aspect(\"auto\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1.1: A standard normal distribution.\n\n\n\n\n\n\n\n\n\nKruschke, John K. 2015. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. 2nd ed. Academic Press.",
    "crumbs": [
      "Concepts and Data Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/01_concepts_and_data_analysis/01_02_basics_of_probability.html",
    "href": "chapters/01_concepts_and_data_analysis/01_02_basics_of_probability.html",
    "title": "2  Basics of probability",
    "section": "",
    "text": "2.1 Random variables\nStatistics is the study of uncertainty. How do we measure uncertainty? Typically we deal with uncertainty by means of probabilities (Kruschke 2015). But what are then probabilities?\nThere are roughly three different frameworks to define probabilities: the classical framework, the frequentist framework, and the Bayesian framework.\nIn general, a probability, under any of these frameworks, is just a way of assigning numbers to a set of mutually exclusive possibilities. The numbers, called “probabilities”, just need to satisfy three properties (Kolmogorov 2018):\nUnder the classical framework, outcomes that are equally likely have equal probabilities. For example, when rolling a fair die, there are six possible outcomes, and they’re all equally likely, thus the probability of rolling a four is just \\(\\mbox{Pr}(X = 4) = \\frac{1}{6}\\).\nUnder the frequentist framework, probabilities are regarded to as long-run relative frequencies.\nSuppose that \\(X\\) represents some unknown quantity of interest. If the value of \\(X\\) is unknown, or could change, we call it a random variable. The set of possible values, denoted \\(\\mathcal{X}\\), is called the sample space. An event is a set of outcomes from a given sample space (Murphy 2022).",
    "crumbs": [
      "Concepts and Data Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of probability</span>"
    ]
  },
  {
    "objectID": "chapters/01_concepts_and_data_analysis/01_02_basics_of_probability.html#random-variables",
    "href": "chapters/01_concepts_and_data_analysis/01_02_basics_of_probability.html#random-variables",
    "title": "2  Basics of probability",
    "section": "",
    "text": "TipExample: random variables\n\n\n\nIf \\(X\\) represents the face of a dice that is rolled, i.e., \\(\\mathcal{X} = \\left\\{1, 2, \\ldots, 6 \\right\\}\\), the event of “seeing a 1” is denoted \\(X = 1\\), the event of “seeing an odd number” is \\(X \\in \\left\\{1, 3, 5 \\right\\}\\).\n\n\n\n2.1.1 Events\nThe expression \\(\\mbox{Pr}(A)\\) is used to denote the probability with which you believe an event \\(A\\) is true. If an event will definitely happen, we write \\(\\mbox{Pr}(A)=1\\) and if an event is definitely not happening we write \\(\\mbox{Pr}(A)=0\\). Furthermore, the probability of \\(A\\) not happening is denoted \\(\\mbox{Pr}(\\bar{A}) = 1 - \\mbox{Pr}(A)\\).\n\n\n\n\nKolmogorov, Andreĭ Nikolaevich. 2018. Foundations of the Theory of Probability: Second English Edition. 2nd ed. Dover Publications.\n\n\nKruschke, John K. 2015. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. 2nd ed. Academic Press.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.",
    "crumbs": [
      "Concepts and Data Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basics of probability</span>"
    ]
  },
  {
    "objectID": "chapters/01_concepts_and_data_analysis/01_03_frequentist_inference.html",
    "href": "chapters/01_concepts_and_data_analysis/01_03_frequentist_inference.html",
    "title": "3  Frequentist inference",
    "section": "",
    "text": "3.1 Confidence intervals\nUnder the frequentist paradigm, we view the data as a random sample from a larger, potentially hypothetical populations.\nLet us assume that we flip a coin 100 times, and we observe 44 heads and 56 tails. We can view these 100 flips as a random sample from a much larger infinite hypothetical population of flips from this coin. In this case we can say that each flip, \\(X_{i}\\), follows a Bournelli distribution with some probability \\(p\\), i.e. \\(X_{i} \\sim \\mbox{Bernoulli}(p)\\).\nWhat is our best estimate of the probability of getting a head, or what is our best estimate of \\(p\\)? We can also ask how confident are we in that estimate. We can start down the mathematical approach by applying the Central Limit Theorem (CLT): \\[\n\\sum_{i}^{100} X_{i} \\underset{\\cdot}{\\overset{\\cdot}{\\sim}} \\mbox{N}(100p, 100p(1-p))\n\\]\nSince we have observed 44 heads, we estimate \\(\\hat{p} = 44/100 = 0.44\\). We use this value to construct a 95% confidence interval (CI): \\[\n\\begin{align}\n(100p - 1.96 \\sqrt{100 p (1 - p)}&, 100p + 1.96 \\sqrt{100 p (1 - p)}) \\\\\n(44 - 1.96 \\sqrt{44 (0.56)}&, 44 + 1.96 \\sqrt{44 (0.56)}) \\\\\n(34.3&, 53.7)\n\\end{align}\n\\]\nWe’re 95% confident that the true probability of getting a head is in this interval. If we ask ourselves whether we think this is a fair coin, then it is reasonable that this is a fair coin because 50 is in this interval.\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats\n\nn_trials = 100\nn_flips = 100\ntrue_p = 0.5\n\np_hat = np.zeros((n_trials,))\nfor i in range(n_trials):\n    xs = scipy.stats.bernoulli(p=true_p).rvs(size=n_flips)\n    p_hat[i] = np.mean(xs)\nsd = [\n    scipy.stats.norm.ppf(0.975) * np.sqrt(n_flips * p_ * (1 - p_)) / n_flips\n    for p_ in p_hat\n]\nlower = p_hat - sd\nupper = p_hat + sd\nmiss = (upper &lt; true_p) | (lower &gt; true_p)\n\nfig, ax = plt.subplots()\nfor i in range(n_trials):\n    color = \"orange\" if miss[i] else \"lightgray\"\n    ax.errorbar(\n        i + 1, \n        p_hat[i], \n        yerr=sd[i],\n        ls=\"none\",\n        marker=\"o\",\n        c=color\n    )\nax.axhline(true_p, ls=\"-\", c=\"r\")\nax.set_xlabel(\"trial\")\nax.set_ylabel(\"$\\hat{p}$\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.1: The 95% confidence interval for 100 coin flips. We expect that the true probability of heads, depicted by the red line at 0.5, is enclosed in about 1 in 20 trials.",
    "crumbs": [
      "Concepts and Data Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Frequentist inference</span>"
    ]
  },
  {
    "objectID": "chapters/01_concepts_and_data_analysis/01_03_frequentist_inference.html#likelihood-function-and-maximum-likelihood",
    "href": "chapters/01_concepts_and_data_analysis/01_03_frequentist_inference.html#likelihood-function-and-maximum-likelihood",
    "title": "3  Frequentist inference",
    "section": "3.2 Likelihood function and maximum likelihood",
    "text": "3.2 Likelihood function and maximum likelihood\nLet’s do another example. Consider a hospital where 400 patients are admitted over a month for heart attacks, and a month later 72 of them have died and 328 of them have survived. We can ask, what’s our estimate of the mortality rate? Under the frequentist paradigm, we must first establish our reference population. What do we think our reference population is here? One possibility is we could think about heart attack patients in the region. Another is we could think about heart attack patients that are admitted to this hospital, but over a longer period of time.\nHow might we do some estimation? We can say each patient comes from a Bernoulli distribution with unknown parameter \\(\\theta\\): \\(Y_{i} \\sim \\mbox{Bernoulli}(\\theta)\\), which means that \\(\\mbox{Pr}(Y_{i}=1) = \\theta\\), where 1 encodes for having died.\nThe probability density function for the entire dataset can be written in vector form: \\[\n\\mbox{Pr}(\\mathbf{Y} = \\mathbf{y} \\mid \\theta) = \\mbox{Pr}(Y_{1} = y_{1}, Y_{2} = y_{2}, \\ldots, Y_{N} = y_{N} \\mid \\theta)\n\\]\nIf we assume each is independent, we can write: \\[\n\\begin{align}\n\\mbox{Pr}(Y_{1} = y_{1}, Y_{2} = y_{2}, \\ldots, Y_{N} = y_{N} \\mid \\theta) &= \\mbox{Pr}(Y_{1} = y_{1} \\mid \\theta)\\ \\mbox{Pr}(Y_{2} = y_{2} \\mid \\theta)\\ \\ldots\\ \\mbox{Pr}(Y_{N} = y_{N} \\mid \\theta) \\\\\n&= \\prod_{i=1}^{N} \\mbox{Pr}(Y_{i} = y_{i} \\mid \\theta) \\\\\n&= \\prod_{i=1}^{N} \\theta^{y_{i}}\\ (1 - \\theta)^{1 - y_{i}} \\\\\n\\end{align}\n\\]\nWe can think of the latter expression as a function of \\(\\theta\\). This is the concept of a likelihood, the density function thought of as a function of the parameters: \\[\nL(\\theta \\mid \\mathbf{y}) = \\prod_{i=1}^{N} \\theta^{y_{i}}\\ (1 - \\theta)^{1 - y_{i}}\n\\]\nOne way to estimate \\(\\theta\\) is to choose the value that gives the largest value of the likelihood. This is referred to as the maximum likelihood estimate (MLE). \\[\n\\hat{\\theta}_{\\mathrm{mle}} = \\arg \\max_{\\theta} L(\\theta \\mid \\mathbf{y})\n\\]\nIn practice it is often easier to maximize the natural logarithm of the likekihood, referred to as the log-likelihood: \\[\n\\ell(\\theta) = \\log L(\\theta \\mid \\mathbf{y})\n\\]\nIn this case: \\[\n\\begin{align}\n\\ell(\\theta) &= \\log\\left( \\prod_{i=1}^{N} \\theta^{y_{i}}\\ (1 - \\theta)^{1 - y_{i}} \\right) \\\\\n&= \\sum_{i=1}^{N} \\log \\left(\\theta^{y_{i}}\\ (1 - \\theta)^{1 - y_{i}} \\right) \\\\\n&= \\sum_{i=1}^{N} y_{i} \\log(\\theta) + (1 - y_{i}) \\log(1 - \\theta) \\\\\n&= \\left(\\sum_{i=1}^{N} y_{i}\\right) \\log(\\theta) + \\left(\\sum_{i=1}^{N} (1 - y_{i})\\right) \\log(1 - \\theta) \\\\\n\\end{align}\n\\]",
    "crumbs": [
      "Concepts and Data Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Frequentist inference</span>"
    ]
  },
  {
    "objectID": "chapters/01_concepts_and_data_analysis/01_03_frequentist_inference.html#computing-the-mle",
    "href": "chapters/01_concepts_and_data_analysis/01_03_frequentist_inference.html#computing-the-mle",
    "title": "3  Frequentist inference",
    "section": "3.3 Computing the MLE",
    "text": "3.3 Computing the MLE\nWe find the maximum log-likelihood by taking the derivative and setting it to zero: \\[\n\\begin{align}\n\\ell'(\\theta) &= \\frac{1}{\\theta} \\left(\\sum_{i=1}^{N} y_{i}\\right) - \\frac{1}{1 - \\theta} \\left(\\sum_{i=1}^{N} (1 - y_{i})\\right) \\overset{\\text{set}}{=} 0 \\\\\n&= \\frac{\\sum_{i=1}^{N} y_{i}}{\\hat{\\theta}} = \\frac{\\sum_{i=1}^{N}(1 - y_{i})}{1 - \\hat{\\theta}} \\\\\n&\\Rightarrow \\hat{\\theta} = \\frac{\\sum_{i=1}^{N}y_{i}}{N}\n\\end{align}\n\\]\n\n\nCode\np_mortality = 72 / 400.\n\n\nThis results in \\(\\hat{p}\\) = 0.18 as the MLE of the probability.",
    "crumbs": [
      "Concepts and Data Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Frequentist inference</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Heiner, Matthew, Herbert Lee, Abel Rodriguez, Raquel Prado, and Jizhou\nKang. n.d. “Bayesian Statistics.” Coursera.\n\n\nKolmogorov, Andreĭ Nikolaevich. 2018. Foundations of the Theory of\nProbability: Second English Edition. 2nd ed. Dover Publications.\n\n\nKruschke, John K. 2015. Doing Bayesian Data Analysis: A Tutorial\nwith r, JAGS, and Stan. 2nd ed. Academic Press.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An\nIntroduction. MIT Press.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "chapters/appendices/binary_variable.html",
    "href": "chapters/appendices/binary_variable.html",
    "title": "Appendix A — Binary variable",
    "section": "",
    "text": "A.1 Bernoulli distribution\nA Bernoulli distribution is used to model a random variable that can take just two discrete values, e.g., heads or tails, or failure or success. Let’s say for example that we have a fair coin. The probability that the coin lands heads up when we toss it, is denoted: \\[\n\\mbox{Pr}(X=x) = \\mbox{Pr}(X=\\mathrm{heads}) = \\theta\n\\]\nand the probability that it lands tails up is: \\[\n\\mbox{Pr}(X=x) = \\mbox{Pr}(X=\\mathrm{tails}) = 1 - \\theta\n\\]\nWe can write this in short as: \\[\n\\mbox{Pr}(X=x) = \\theta^{x}\\ (1 - \\theta)^{1-x}\n\\]\nIn general, the function that computes the probability of events which correspond to setting the random variable to each possible value is referred to as the probability mass function (pmf) (Murphy 2022): \\[\np(x) \\triangleq \\mbox{Pr}(X=x)\n\\]\nThe expected value of a Bernoulli random variable is: \\[\n\\begin{align}\n\\mathbb{E}[X] &= \\sum_{x \\in \\mathcal{X}} x p(x) \\\\\n&= (0) (1 - \\theta) + (1) (\\theta) = \\theta\n\\end{align}\n\\]\nThe variance, that is a measure of the spread of a distribution, is: \\[\n\\begin{align}\n\\mathbb{V}[X] &= \\mathbb{E}[X^{2}] - \\mathbb{E}[X]^{2} \\\\\n\\mathbb{E}[X^{2}] &= \\sum_{x \\in \\mathcal{X}} x^{2}\\ p(x) \\\\\n&= (0)^{2} (1 - \\theta) + (1)^{2} (\\theta) = \\theta \\\\\n\\mathbb{V}[X] &= \\mathbb{E}[X^{2}] - \\mathbb{E}[X]^{2} \\\\\n&= \\theta - \\theta^{2} = \\theta (1 - \\theta)\n\\end{align}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Binary variable</span>"
    ]
  },
  {
    "objectID": "chapters/appendices/binary_variable.html#binomial-distribution",
    "href": "chapters/appendices/binary_variable.html#binomial-distribution",
    "title": "Appendix A — Binary variable",
    "section": "A.2 Binomial distribution",
    "text": "A.2 Binomial distribution\nThe generalization of the Bernoulli random variables, is the binomial distribution where we have \\(N\\) repeated trials. Suppose we flip a coin ten times, what is the probability of observing heads, heads, tails, heads, … We can model the number of heads, \\(X\\), as a function of the number of trials, \\(N\\), and the probability of success, \\(\\theta\\): \\[\np(x \\mid N, \\theta) = \\binom{N}{x} \\theta^{x} (1 - \\theta)^{1-x}\n\\]\nFurthermore, for the binomial distribution we have: \\[\n\\begin{align}\n\\mathbb{E}[X] &= n \\theta \\\\\n\\mathbb{V}[X] &= n \\theta (1 - \\theta)\n\\end{align}\n\\]\n\n\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Binary variable</span>"
    ]
  },
  {
    "objectID": "chapters/appendices/continuous_variable.html",
    "href": "chapters/appendices/continuous_variable.html",
    "title": "Appendix B — Continuous random variable",
    "section": "",
    "text": "B.1 Uniform distribution\nWe define the cumulative distribution function (cdf): \\[\nP(x) = \\mbox{Pr}(X \\le x)\n\\]\nThe probability density function (pdf) is defined as the derivative of the cdf: \\[\np(x) \\triangleq \\frac{\\mathrm{d}}{\\mathrm{d}x}P(x)\n\\]\nFor any continuous random variable it holds that: \\[\n\\int_{-\\infty}^{\\infty} p(x)\\ \\mathrm{d}x = 1\n\\]\nand \\(p(x) \\ge 0\\).\n\\[\n\\begin{align}\nX &\\sim \\mbox{Uniform}(a, b) \\\\\np(x \\mid a, b) &= \\frac{1}{b - a}, \\quad a \\le x \\le b\n\\end{align}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Continuous random variable</span>"
    ]
  },
  {
    "objectID": "chapters/appendices/continuous_variable.html#exponential-distribution",
    "href": "chapters/appendices/continuous_variable.html#exponential-distribution",
    "title": "Appendix B — Continuous random variable",
    "section": "B.2 Exponential distribution",
    "text": "B.2 Exponential distribution\nThe exponential distribution can be used to model events that occur at a particular rate. For example, the waiting time for the bus the come.\n\\[\n\\begin{align}\nX &\\sim \\mbox{Exp}(\\lambda) \\\\\np(x \\mid \\lambda) &= \\lambda e^{-\\lambda x}, \\quad x \\ge 0 \\\\\n\\mathbb{E}[X] &= 1 / \\lambda \\\\\n\\mathbb{V}[X] &= 1 / \\lambda^{2}\n\\end{align}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Continuous random variable</span>"
    ]
  },
  {
    "objectID": "chapters/appendices/continuous_variable.html#normal-distribution",
    "href": "chapters/appendices/continuous_variable.html#normal-distribution",
    "title": "Appendix B — Continuous random variable",
    "section": "B.3 Normal distribution",
    "text": "B.3 Normal distribution\n\\[\n\\begin{align}\nX &\\sim \\mbox{Normal}(\\mu, \\sigma) \\\\\np(x \\mid \\mu, \\sigma) &= \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{-\\frac{1}{2 \\sigma^{2}} \\left(x - \\mu\\right)^{2}\\right\\} \\\\\n\\mathbb{E}[X] &= \\mu \\\\\n\\mathbb{V}[X] &= \\sigma^{2}\n\\end{align}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Continuous random variable</span>"
    ]
  }
]